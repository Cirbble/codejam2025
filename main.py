"""Main script to run the memecoin sentiment scraper."""
from src.reddit_scraper import RedditScraper
from src.config import MEMECOIN_SUBREDDITS


def main():
    """Run the scraper."""
    print("ðŸš€ Starting Memecoin Sentiment Scraper...")
    print(f"ðŸ“‹ Monitoring {len(MEMECOIN_SUBREDDITS)} subreddits\n")
    
    scraper = RedditScraper()
    output_file = "scraped_posts.json"
    
    # Scrape all subreddits (saves in real-time)
    posts = scraper.scrape_all_subreddits(
        limit_per_subreddit=10,
        scrape_comments=True,
        take_screenshots=False,
        output_file=output_file
    )
    
    # Final save (already saved incrementally, but ensure it's up to date)
    scraper.to_json(posts, output_file)
    
    # Display summary
    print("\n" + "="*60)
    print("SCRAPED POSTS SUMMARY")
    print("="*60)
    
    for i, post in enumerate(posts[:10], 1):  # Show first 10
        print(f"\n{i}. [{post.source}] {post.title}")
        print(f"   â¬†ï¸ {post.upvotes_likes} | ðŸ’¬ {post.comment_count} | ðŸ‘¤ {post.author or 'unknown'}")
        if post.comments:
            print(f"   ðŸ’¬ Comments: {len(post.comments)}")
    
    if len(posts) > 10:
        print(f"\n... and {len(posts) - 10} more posts")
    
    print(f"\nðŸ“„ Full JSON saved to scraped_posts.json")


if __name__ == "__main__":
    main()

